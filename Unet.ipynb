{"cells":[{"cell_type":"markdown","metadata":{"id":"YALdomdheOzl"},"source":["# U-Net\n","This notebook trains and evaluates a U-Net model for bladder neck dissection segmentation.\n","\n"]},{"cell_type":"markdown","source":["### 0. Access Google Drive on Google Colab\n","Mount Google Drive to access the dataset stored in your Drive."],"metadata":{"id":"OKW_6X4gzqSz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_UacYFZpx1n"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["---\n","\n","### 1. Import Libraries"],"metadata":{"id":"nO7p9k1Kz4Em"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcK-KLfUp1yo"},"outputs":[],"source":["!pip install labelme tensorflow matplotlib numpy opencv-python scikit-learn\n","!pip install --upgrade tensorflow # upgrade tensorflow\n","\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, Input  # Removed problematic imports\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation# Import them directly from layers\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import MeanIoU\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import Resizing\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.applications.xception import preprocess_input\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import jaccard_score\n","from sklearn.utils import shuffle\n","import json\n","from PIL import Image\n","import cv2\n","import random\n","from IPython.display import clear_output\n","import time\n","import datetime\n","import pandas as pd\n","pd.set_option('display.max_colwidth', None)"]},{"cell_type":"markdown","source":["### Image and Mask Loader\n","\n","This class loads surgical images and their corresponding segmentation masks\n","(from LabelMe JSON annotations).  "],"metadata":{"id":"RT9mXWQn89g9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TD4lXsjcoa6u"},"outputs":[],"source":["class ImageMaskLoader:\n","    def __init__(self, data_root, folders, labels, resize_height=256, resize_width=256, background_label=0):\n","        self.data_root = data_root\n","        self.folders = folders\n","        self.labels = labels\n","        self.resize_height = resize_height\n","        self.resize_width = resize_width\n","        self.background_label = background_label\n","\n","    def load_and_process_data(self):\n","        images = []\n","        masks = []\n","\n","        for folder in self.folders:\n","            folder_path = os.path.join(self.data_root, folder)\n","            for file in os.listdir(folder_path):\n","                if file.endswith(\".jpg\"):\n","                    image_path = os.path.join(folder_path, file)\n","                    json_path = image_path.replace(\".jpg\", \".json\")\n","\n","                    image = cv2.imread(image_path)\n","                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","                    original_height, original_width = image.shape[:2]\n","                    image_resized = cv2.resize(image, (self.resize_width, self.resize_height))\n","\n","                    if not os.path.exists(json_path):\n","                        print(f\"{file} has no corresponding JSON file. Using background mask.\")\n","                        mask = np.full((self.resize_height, self.resize_width), self.background_label, dtype=np.uint8)\n","                    else:\n","                        with open(json_path) as f:\n","                            data = json.load(f)\n","                            mask = np.full((self.resize_height, self.resize_width), self.background_label, dtype=np.uint8)\n","\n","                            for shape in data['shapes']:\n","                                label = shape['label']\n","                                if label in self.labels:\n","                                    points = np.array(shape['points'], dtype=np.int32)\n","                                    points[:, 0] = (points[:, 0] * self.resize_width / original_width).astype(int)\n","                                    points[:, 1] = (points[:, 1] * self.resize_height / original_height).astype(int)\n","                                    cv2.fillPoly(mask, [points], self.labels[label])\n","\n","                    images.append(img_to_array(image_resized))\n","                    masks.append(mask)\n","\n","        images = np.array(images, dtype=\"float32\") / 255.0\n","        masks = np.array(masks, dtype=\"int32\")\n","        masks = np.expand_dims(masks, axis=-1)\n","        masks = to_categorical(masks, num_classes=len(self.labels))\n","\n","        return images, masks"]},{"cell_type":"markdown","source":["- **DATA_ROOT**: Root directory of the dataset on Google Drive.  \n","- **FOLDERS**: List of subfolders for training data.  "],"metadata":{"id":"CYz402eRrUhv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsXiZDx2Tb1I"},"outputs":[],"source":["DATA_ROOT = '/content/drive/MyDrive/your_path'\n","\n","FOLDERS   = []\n","\n","LABELS = {\n","    \"background\": 0,\n","    \"bladder\": 1,\n","    \"border\": 2,\n","    \"catheter\": 3,\n","    \"gauze\": 4,\n","    \"instrument\": 5,\n","    \"mucosa\": 6,\n","    \"prostate\": 7,\n","    \"suction\": 8,\n","    \"urethra\": 9,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4G1aS8Roo8b"},"outputs":[],"source":["loader = ImageMaskLoader(DATA_ROOT, FOLDERS, LABELS)\n","images, masks = loader.load_and_process_data()"]},{"cell_type":"markdown","source":["### Train / Test Split"],"metadata":{"id":"DK-vktb19Ya8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOfF30NqQLtr"},"outputs":[],"source":["train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","source":["### IoU Calculator\n","This class provides functions to calculate Intersection over Union (IoU)."],"metadata":{"id":"RawjfjR08t6x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mwBUfAoowa1"},"outputs":[],"source":["class IoUCalculator:\n","    def __init__(self, num_classes):\n","        self.num_classes = num_classes\n","\n","    def calculate_iou(self, y_true, y_pred):\n","        iou_metric = MeanIoU(num_classes=self.num_classes)\n","        iou_metric.update_state(y_true, y_pred)\n","        return iou_metric.result().numpy()\n","\n","    def calculate_class_iou(self, test_masks, y_pred_argmax, class_index):\n","        y_true_class = (np.argmax(test_masks, axis=-1) == class_index).astype(np.uint8)\n","        y_pred_class = (y_pred_argmax == class_index).astype(np.uint8)\n","        iou = self.calculate_iou(y_true_class, y_pred_class)\n","        return iou\n","\n","    def calculate_mean_iou(self, test_masks, y_pred_argmax):\n","        class_ious = []\n","        for cls_idx in range(self.num_classes):\n","            iou = self.calculate_class_iou(test_masks, y_pred_argmax, cls_idx)\n","            class_ious.append(iou)\n","        mean_iou = np.nanmean(class_ious)\n","        return mean_iou"]},{"cell_type":"markdown","source":["### U-Net Model Definition\n","This block defines the U-Net architecture.  \n"],"metadata":{"id":"_FKTFsAq-1Lw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"etVNfQ7DhOoc"},"outputs":[],"source":["# Unet\n","def unet_model(input_shape=(256, 256, 3), num_classes=10):\n","    inputs = Input(input_shape)\n","\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n","\n","    u6 = UpSampling2D((2, 2))(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","\n","    u7 = UpSampling2D((2, 2))(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","\n","    u8 = UpSampling2D((2, 2))(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","\n","    u9 = UpSampling2D((2, 2))(c8)\n","    u9 = concatenate([u9, c1])\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","\n","    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n","\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","\n","    return model\n","\n","model = unet_model()\n","model.summary()"]},{"cell_type":"markdown","source":["### Training Configuration\n","\n","- **Learning Rate Scheduler**  \n","  \n","- **Early Stopping**  \n","  \n","- **Optimizer**  "],"metadata":{"id":"2znhz6Lc_LD1"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RwOJk3vuqP2P"},"outputs":[],"source":["def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * 0.99\n","\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","initial_learning_rate = 0.001\n","optimizer = Adam(learning_rate=initial_learning_rate)"]},{"cell_type":"markdown","source":["### Model Construction and Compilation"],"metadata":{"id":"S-nsIeFQ_j4r"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_kP5RMh8TN_4"},"outputs":[],"source":["input_shape = (256, 256, 3)\n","num_classes = len(labels)\n","\n","model = unet_model(input_shape=input_shape, num_classes=num_classes)\n","\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"markdown","source":["### Model Training, Monitoring, and Saving"],"metadata":{"id":"6nEBV_K4BIp8"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M9kmIAMC0PYL"},"outputs":[],"source":["start_time = time.time()\n","\n","history = model.fit(\n","    train_images,\n","    train_masks,\n","    validation_data=(test_images, test_masks),\n","    batch_size=8,\n","    epochs=50,\n","    callbacks=[lr_scheduler, early_stopping]\n",")\n","\n","\n","end_time = time.time()\n","\n","training_time = end_time - start_time\n","\n","print(f\"Training time: {training_time:.2f} seconds\")\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","model_path = '/content/drive/MyDrive/your_path/Unet.h5'\n","model.save(model_path)"]},{"cell_type":"markdown","source":["### Model Evaluation (IoU Calculation)\n","\n","Evaluate the trained model on the test set using Intersection over Union (IoU):"],"metadata":{"id":"usi8ojrpBPjs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hyki9jcQv7LN"},"outputs":[],"source":["num_classes =  len(labels)\n","iou_calculator = IoUCalculator(num_classes)\n","y_pred = model.predict(test_images)\n","y_pred_argmax = np.argmax(y_pred, axis=-1)\n","iou_bladder = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=1)\n","iou_prostate = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=7)\n","iou_border = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=2)\n","iou_catheter = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=3)\n","iou_gauze = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=4)\n","iou_instrument = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=5)\n","iou_mucosa = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=6)\n","iou_suction = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=8)\n","iou_urethra = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=9)\n","iou_background = iou_calculator.calculate_class_iou(test_masks, y_pred_argmax, class_index=0)\n","mean_iou = iou_calculator.calculate_mean_iou(test_masks, y_pred_argmax)\n","print(f\"Mean IoU: {mean_iou}\")\n","print(f\"IoU for Bladder: {iou_bladder}\")\n","print(f\"IoU for Prostate: {iou_prostate}\")\n","print(f\"IoU for Border: {iou_border}\")\n","print(f\"IoU for Catheter: {iou_catheter}\")\n","print(f\"IoU for Gauze: {iou_gauze}\")\n","print(f\"IoU for Instrument: {iou_instrument}\")\n","print(f\"IoU for Mucosa: {iou_mucosa}\")\n","print(f\"IoU for Suction: {iou_suction}\")\n","print(f\"IoU for Urethra: {iou_urethra}\")\n","print(f\"IoU for Background: {iou_background}\")"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPqDUtdyjhS/yL0+vUXFl3H"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}